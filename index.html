<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Tony  Ng


</title>
<meta name="description" content="Academic portfolio site of Tony Ng, computer vision researcher.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Fraunces:opsz,wght@9..144,300;400;500;600;700&family=Space+Grotesk:wght@300;400;500;600;700&display=swap">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ†–</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://tonyng.vision/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                submenus
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/publications/">publications</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/cv/">curriculum vitae</a>
              
              
              </div>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/">
                CV
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                fun corner
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/play/">diffusion toy</a>
              
              
              
                <a class="dropdown-item" href="/wake-vortex/">wake vortex</a>
              
              
              </div>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post home">
  <header class="post-header home-header">
    <div class="home-hero">
      <p class="home-kicker">Computer Vision + Generative AI</p>
      <h1 class="home-title">Tony Ng</h1>
      <p class="home-subtitle">AI Research Scientist at Meta, building diffusion systems for image, video, and audio generation at scale.</p>
      <div class="home-cta">
        
        <a class="home-cta-btn primary" href="/cv/">
          View CV
        </a>
        
        <a class="home-cta-btn" href="/publications/">
          Publications
        </a>
        
        <a class="home-cta-btn" href="/play/">
          Fun Corner
        </a>
        
      </div>
      
      <div class="home-hero-media">
        
          
          <img class="img-fluid home-hero-image" src="/assets/img/gmfD0li0G0Y2CRPK.png" alt="Tony Ng">
        
      </div>
      
    </div>
    <p class="home-description">AI Research Scientist at Meta. PhD at <a href="https://www.imperial.ac.uk/matchlab/" target="_blank" rel="noopener noreferrer">MatchLab, Imperial College London</a>. Ex-Synthesia &amp; Scape Technologies.</p>
  </header>

  <article class="home-content">
    <section class="home-section">
  <h2>Research Focus</h2>
  <div class="home-cards">
    <div class="home-card">
      <h3>Generative Systems</h3>
      <p>Diffusion models for image, video, and audio generation with real-world quality and reliability constraints.</p>
    </div>
    <div class="home-card">
      <h3>Visual Localization</h3>
      <p>Learning-based localization that blends geometry with deep representations for AR/VR at scale.</p>
    </div>
    <div class="home-card">
      <h3>Privacy + Security</h3>
      <p>Content-concealing descriptors and robust perception for privacy-preserving visual systems.</p>
    </div>
  </div>
</section>

<section class="home-section">
  <h2>Now</h2>
  <p>
    I build and evaluate diffusion systems for ad creatives at Meta AI Research. Iâ€™m interested in controllable generation,
    scalable data curation, and evaluation frameworks that move beyond surface-level metrics.
  </p>
  <p>
    Iâ€™m open to collaborations on generative media systems, privacy-preserving perception, and robust evaluation.
  </p>
</section>


    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  </div>

  <div id="ng2021ninjadesc" class="col-sm-8">
    
      <div class="title">NinjaDesc: Content-Concealing Visual Descriptors via Adversarial Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hyo Jin Kim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vincent Lee,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Daniel DeTone,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tsun-Yi Yang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tianwei Shen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Eddy Ilg,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chris Sweeney
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In CVPR</em>,
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2112.12785" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In the light of recent analyses on privacy-concerning scene revelation from visual descriptors, we develop descriptors that conceal the input image content. In particular, we propose an adversarial learning framework for training visual descriptors that prevent image reconstruction, while maintaining the matching accuracy. We let a feature encoding network and image reconstruction network compete with each other, such that the feature encoder tries to impede the image reconstruction with its generated descriptors, while the reconstructor tries to recover the input image from the descriptors. The experimental results demonstrate that the visual descriptors obtained with our method significantly deteriorate the image reconstruction quality with minimal impact on correspondence matching and camera localization performance.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="ng2021reassessing" class="col-sm-8">
    
      <div class="title">Reassessing the Limitations of CNN Methods for Camera Pose Regression</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adrian Lopez-Rodriguez,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint</em>,
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2108.07260" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we address the problem of camera pose estimation in outdoor and indoor scenarios. In comparison to the currently top-performing methods that rely on 2D to 3D matching, we propose a model that can directly regress the camera pose from images with significantly higher accuracy than existing methods of the same class. We first analyse why regression methods are still behind the state-of-the-art, and we bridge the performance gap with our new approach. Specifically, we propose a way to overcome the biased training data by a novel training technique, which generates poses guided by a probability distribution from the training set for synthesising new training views. Lastly, we evaluate our approach on two widely used benchmarks and show that it achieves significantly improved performance compared to prior regression-based methods, retrieval techniques as well as 3D pipelines with local feature matching.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ECCV</abbr>
    
  
  </div>

  <div id="ng2020solar" class="col-sm-8">
    
      <div class="title">SOLAR: Second-Order Loss and Attention for Image Retrieval</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yurun Tian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ECCV</em>,
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2001.08972" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
      <a href="https://opencv.org/utilising-second-order-information-for-deep-image-retrieval/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a>
    
    
      <a href="https://github.com/tonyngjichun/SOLAR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent works in deep-learning have shown that second-order information is beneficial in many computer-vision tasks. Second-order information can be enforced both in the spatial context and the abstract feature dimensions. In this work, we explore two second-order components. One is focused on second-order spatial information to increase the performance of image descriptors, both local and global. It is used to re-weight feature maps, and thus emphasise salient image locations that are subsequently used for description. The second component is concerned with a second-order similarity (SOS) loss, that we extend to global descriptors for image retrieval, and is used to enhance the triplet loss with hard-negative mining. We validate our approach on two different tasks and datasets for image retrieval and image matching. The results show that our two second-order components complement each other, bringing significant performance improvements in both tasks and lead to state-of-the-art results across the public benchmarks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Dec 10, 2025</th>
          <td>
            
              New preprint: TUNA â€” Taming Unified Visual Representations for Native Unified Multimodal Models (arXiv:2512.02014).

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug 1, 2024</th>
          <td>
            
              Started a new role as an AI Research Scientist at Meta, focusing on diffusion models for image, video, and audio generation.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 1, 2023</th>
          <td>
            
              Joined Synthesia as a Research Engineer, working on controllable video diffusion models for AI dubbing on avatars.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 7, 2022</th>
          <td>
            
              I completed a second research internship at Reality Labs, this time working on multi-modal understanding (text &amp; geometry) using language models.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 24, 2022</th>
          <td>
            
              Our paper <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_NinjaDesc_Content-Concealing_Visual_Descriptors_via_Adversarial_Learning_CVPR_2022_paper.pdf" target="_blank" rel="noopener noreferrer">NinjaDesc: Content-Concealing Visual Descriptors via Adversarial Learning</a> was presented at CVPR 2022, New Orleans LA.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%74%6E%31%32%31%34@%69%63.%61%63.%75%6B" title="email"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=user=P4S4IokAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/tonyngjichun" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/tony-n-b88b1512b" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/tonyngjichun" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>













      </div>
      <div class="contact-note">Feel free to contact me via email, Twitter or LinkedIn DM :)
</div>
    </div>
    
  </article>
</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    Â© Copyright 2026 Tony  Ng.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: February 10, 2026.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
