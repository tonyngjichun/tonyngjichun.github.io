<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Tony  Ng


  | publications

</title>
<meta name="description" content="Academic portfolio site of Tony Ng, computer vision researcher.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Fraunces:opsz,wght@9..144,300;400;500;600;700&family=Space+Grotesk:wght@300;400;500;600;700&display=swap">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ†–</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://tonyng.vision/publications/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://tonyng.vision/">
       <span class="font-weight-bold">Tony</span>   Ng
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                submenus
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/publications/">publications</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/cv/">curriculum vitae</a>
              
              
              </div>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/">
                CV
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                fun corner
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/play/">diffusion toy</a>
              
              
              
                <a class="dropdown-item" href="/wake-vortex/">wake vortex</a>
              
              
              </div>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">Please also check my <a href="https://scholar.google.com/citations?user=P4S4IokAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Google Scholar profile</a> for an up-to-date list.</p>
  </header>

  <article>
    <div class="publications">
  <p class="text-muted">Last updated: January 2026.</p>


  <h2 class="year">2025</h2>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="liu2025tuna" class="col-sm-8">
    
      <div class="title">TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Z Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  W Ren,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  H Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Z Zhou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  S Chen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  H Qiu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  X Huang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Z An,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  F Yang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                   others
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint</em>,
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2512.02014" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Patent</abbr>
    
  
  </div>

  <div id="kim2023arvrpatent" class="col-sm-8">
    
      <div class="title">Systems and Methods for Providing User Experiences on AR/VR Systems</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Hyo Jin Kim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vincent Lee,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  F E R Ilg,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  S El Ghazzal,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Z Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Z Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  P K Huang
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  </div>

  <div id="ng2021ninjadesc" class="col-sm-8">
    
      <div class="title">NinjaDesc: Content-Concealing Visual Descriptors via Adversarial Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hyo Jin Kim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vincent Lee,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Daniel DeTone,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tsun-Yi Yang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tianwei Shen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Eddy Ilg,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chris Sweeney
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In CVPR</em>,
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2112.12785" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In the light of recent analyses on privacy-concerning scene revelation from visual descriptors, we develop descriptors that conceal the input image content. In particular, we propose an adversarial learning framework for training visual descriptors that prevent image reconstruction, while maintaining the matching accuracy. We let a feature encoding network and image reconstruction network compete with each other, such that the feature encoder tries to impede the image reconstruction with its generated descriptors, while the reconstructor tries to recover the input image from the descriptors. The experimental results demonstrate that the visual descriptors obtained with our method significantly deteriorate the image reconstruction quality with minimal impact on correspondence matching and camera localization performance.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">3DV</abbr>
    
  
  </div>

  <div id="ng2022oodpose" class="col-sm-8">
    
      <div class="title">OoD-Pose: Camera Pose Regression from Out-of-Distribution Synthetic Views</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adrian Lopez-Rodriguez,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2022 International Conference on 3D Vision (3DV)</em>,
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="nazarczuk2022samplehd" class="col-sm-8">
    
      <div class="title">SAMPLE-HD: Simultaneous Action and Motion Planning Learning Environment</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  M Nazarczuk,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint</em>,
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2206.10312" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="ng2021reassessing" class="col-sm-8">
    
      <div class="title">Reassessing the Limitations of CNN Methods for Camera Pose Regression</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adrian Lopez-Rodriguez,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint</em>,
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2108.07260" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we address the problem of camera pose estimation in outdoor and indoor scenarios. In comparison to the currently top-performing methods that rely on 2D to 3D matching, we propose a model that can directly regress the camera pose from images with significantly higher accuracy than existing methods of the same class. We first analyse why regression methods are still behind the state-of-the-art, and we bridge the performance gap with our new approach. Specifically, we propose a way to overcome the biased training data by a novel training technique, which generates poses guided by a probability distribution from the training set for synthesising new training views. Lastly, we evaluate our approach on two widely used benchmarks and show that it achieves significantly improved performance compared to prior regression-based methods, retrieval techniques as well as 3D pipelines with local feature matching.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ECCV</abbr>
    
  
  </div>

  <div id="ng2020solar" class="col-sm-8">
    
      <div class="title">SOLAR: Second-Order Loss and Attention for Image Retrieval</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yurun Tian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ECCV</em>,
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2001.08972" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
      <a href="https://opencv.org/utilising-second-order-information-for-deep-image-retrieval/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a>
    
    
      <a href="https://github.com/tonyngjichun/SOLAR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent works in deep-learning have shown that second-order information is beneficial in many computer-vision tasks. Second-order information can be enforced both in the spatial context and the abstract feature dimensions. In this work, we explore two second-order components. One is focused on second-order spatial information to increase the performance of image descriptors, both local and global. It is used to re-weight feature maps, and thus emphasise salient image locations that are subsequently used for description. The second component is concerned with a second-order similarity (SOS) loss, that we extend to global descriptors for image retrieval, and is used to enhance the triplet loss with hard-negative mining. We validate our approach on two different tasks and datasets for image retrieval and image matching. The results show that our two second-order components complement each other, bringing significant performance improvements in both tasks and lead to state-of-the-art results across the public benchmarks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="tian2020hynet" class="col-sm-8">
    
      <div class="title">HyNet: Learning Local Descriptor with Hybrid Similarity Measure and Triplet Loss</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Yurun Tian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Axel Barroso-Laguna,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In NeurIPS</em>,
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2006.10202" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://github.com/yuruntian/HyNet" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent works show that local descriptor learning benefits from the use of L2 normalisation, however, an in-depth analysis of this effect lacks in the literature. In this paper, we investigate how L2 normalisation affects the back-propagated descriptor gradients during training. Based on our observations, we propose HyNet, a new local descriptor that leads to state-of-the-art results in matching. HyNet introduces a hybrid similarity measure for triplet margin loss, a regularisation term constraining the descriptor norm, and a new network architecture that performs L2 normalisation of all intermediate feature maps and the output descriptors. HyNet surpasses previous methods by a significant margin on standard benchmarks that include patch matching, verification, and retrieval, as well as outperforming full end-to-end methods on 3D reconstruction tasks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ACCV</abbr>
    
  
  </div>

  <div id="tian2020d2d" class="col-sm-8">
    
      <div class="title">D2D: Keypoint Extraction with Describe to Detect Approach</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Yurun Tian,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://vbalnt.github.io/" target="_blank" rel="noopener noreferrer">Vassileios Balntas</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Tony Ng</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Axel Barroso-Laguna,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yiannis Demiris,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krystian Mikolajczyk
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Asian Conference on Computer Vision (ACCV)</em>,
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2005.13605" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we present a novel approach that exploits the information within the descriptor space to propose keypoint locations. Detect then describe, or detect and describe jointly are two typical strategies for extracting local descriptors. In contrast, we propose an approach that inverts this process by first describing and then detecting the keypoint locations. % Describe-to-Detect (D2D) leverages successful descriptor models without the need for any additional training. Our method selects keypoints as salient locations with high information content which is defined by the descriptors rather than some independent operators. We perform experiments on multiple benchmarks including image matching, camera localisation, and 3D reconstruction. The results indicate that our method improves the matching performance of various descriptors and that it generalises across methods and tasks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    Â© Copyright 2026 Tony  Ng.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: February 10, 2026.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
